{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Koopstrap\n\n\nKootstrap is a bootstrap to \nKeras\n. It is a technique of compile and loading a datasets into a Keras application by means of a few initial instructions that enable the introduction of the rest of the program from an input device\n\n\nCommands\n\n\nCreate a dataset\n with two classes.\n\n\ncd maker/\npython Main.py --mode dataset --dataset_name graffiti --classes graffiti,street\n\n\n\nCreate a subset\n of this dataset with 90% original images\n\n\npython Main.py --mode compiler  --dataset_name graffiti --subset_name graffiti_per90_porp_default --per_images 90\n\n\n\nCrawls images\n to each class from Flickr. This seed the dataset and compile the subsets.\n\n\ncd ../crawler/\npython Main.py --mode crawler,dataset --dataset dataset_example --classes graffiti,street --flickr_tags graffiti,street\\ art;street --num_images 100\n\n\n\nExecute a train\n with finetuning in Imagenet Model\n\n\ncd ../trainer/\npython Main.py --model_name model_example_1 --load_data dataset_example\n\n\n\nTest the predictions\n on model with set of test compileted in \ngraffiti_per90_porp_default\n\n\ncd ../tester/\npython Main.py --model_name model_example_1 --load_data graffiti_per90_porp_default\n\n\n\nCompile a 1-Top\n with a histogram from test results:\n\n\ncd ../analyzer/\npython Main.py --model_name top --test_name testing_imagenet_test_set\n\n\n\nMigrate datasets\n\n\nif you have a dataset and want migrate try:\n\n\ncd ../tools/\npython Main.py --mode migrate --path_origin \nPATH_FOLDER_WITH_CLASSES\n --path_destiny \nPATH_TO_KOOTSTRAP_FOLDER\n\n\n\n\nif you want create a subset or recovery the \nmetadata.json\n try:\n\n\ncd ../tools/\npython Main.py --mode fix --path_origin \nPATH_TO_SUBSET_OR_DATASET\n\n\n\n\nProject layout\n\n\ndata/           # folder with all data generate by applications.\n    configs/\n    models/\n    datasets/\n    tests/\n    others/\napplications/   # applications suches crawler, analyzers etc\n    analyzer/\n    crawler/\n    maker/\n    system/\n    tester/\n    tools/\n    trainer/\ndocs/           # documentation of kootstrap\nmkdocs/         # generator of documentation", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-koopstrap", 
            "text": "Kootstrap is a bootstrap to  Keras . It is a technique of compile and loading a datasets into a Keras application by means of a few initial instructions that enable the introduction of the rest of the program from an input device", 
            "title": "Welcome to Koopstrap"
        }, 
        {
            "location": "/#commands", 
            "text": "Create a dataset  with two classes.  cd maker/\npython Main.py --mode dataset --dataset_name graffiti --classes graffiti,street  Create a subset  of this dataset with 90% original images  python Main.py --mode compiler  --dataset_name graffiti --subset_name graffiti_per90_porp_default --per_images 90  Crawls images  to each class from Flickr. This seed the dataset and compile the subsets.  cd ../crawler/\npython Main.py --mode crawler,dataset --dataset dataset_example --classes graffiti,street --flickr_tags graffiti,street\\ art;street --num_images 100  Execute a train  with finetuning in Imagenet Model  cd ../trainer/\npython Main.py --model_name model_example_1 --load_data dataset_example  Test the predictions  on model with set of test compileted in  graffiti_per90_porp_default  cd ../tester/\npython Main.py --model_name model_example_1 --load_data graffiti_per90_porp_default  Compile a 1-Top  with a histogram from test results:  cd ../analyzer/\npython Main.py --model_name top --test_name testing_imagenet_test_set", 
            "title": "Commands"
        }, 
        {
            "location": "/#migrate-datasets", 
            "text": "if you have a dataset and want migrate try:  cd ../tools/\npython Main.py --mode migrate --path_origin  PATH_FOLDER_WITH_CLASSES  --path_destiny  PATH_TO_KOOTSTRAP_FOLDER   if you want create a subset or recovery the  metadata.json  try:  cd ../tools/\npython Main.py --mode fix --path_origin  PATH_TO_SUBSET_OR_DATASET", 
            "title": "Migrate datasets"
        }, 
        {
            "location": "/#project-layout", 
            "text": "data/           # folder with all data generate by applications.\n    configs/\n    models/\n    datasets/\n    tests/\n    others/\napplications/   # applications suches crawler, analyzers etc\n    analyzer/\n    crawler/\n    maker/\n    system/\n    tester/\n    tools/\n    trainer/\ndocs/           # documentation of kootstrap\nmkdocs/         # generator of documentation", 
            "title": "Project layout"
        }, 
        {
            "location": "/maker/", 
            "text": "Maker\n\n\nThe maker help you to create a dataset and subsets used to train or test. Try execute the \nMain.py\n class.\n\n\nCommands\n\n\nStart to create a dataset with two classes.\n\n\npython Main.py --mode dataset --dataset_name graffiti --classes graffiti,street\n\n\n\nCreate a subset of this dataset with 90% original images\n\n\npython Main.py --mode compiler  --dataset_name graffiti --subset_name graffiti_per90_porp_default --per_images 90\n\n\n\nArguments\n\n\n\n\n\n\n--mode\n: Use \ndataset\n to create a new and \ncompiler\n to subsets.\n\n\n\n\n\n\n--dataset_name\n: Name used to dataset. Default \ndataset_example\n.\n\n\n\n\n\n\n--classes_load_file\n: If not empty load form file the name of classes.\n\n\n\n\n\n\n--classes\n: if empty and --classes_load_file empty the Compiler use all classes inside the dataset. Separete classes wite comma.\n\n\n\n\n\n\n--subset_name\n: name of subset. If not passed will setted as \ndataset_name\n_\nserial_data\n.\n\n\n\n\n\n\n--num_images\n: Number of images from dataset. If negative use --per_images else both negative use all images.\n\n\n\n\n\n\n--per_images\n: percent of images from dataset [-1,100]. If negative use --num_images else both negative use all images.\n\n\n\n\n\n\n--scissor\n: if scissor is on will cut images has configs scissor.json else keep the image on exactly same size (only copy).\n\n\n\n\n\n\n--train_proportional_size\n: size of train, default 70%, setted if test exists.\n\n\n\n\n\n\n--validation_proportional_size\n: size of validation, default 20%, setted if validation exists. Zero if dont want validation\n\n\n\n\n\n\n--test_proportional_size\n: size of validation, default 20%, setted if test exists. Zero if dont want test \n\n\n\n\n\n\n--annotation\n: text annotation used you to describe the subset.", 
            "title": "About compiler"
        }, 
        {
            "location": "/maker/#maker", 
            "text": "The maker help you to create a dataset and subsets used to train or test. Try execute the  Main.py  class.", 
            "title": "Maker"
        }, 
        {
            "location": "/maker/#commands", 
            "text": "Start to create a dataset with two classes.  python Main.py --mode dataset --dataset_name graffiti --classes graffiti,street  Create a subset of this dataset with 90% original images  python Main.py --mode compiler  --dataset_name graffiti --subset_name graffiti_per90_porp_default --per_images 90", 
            "title": "Commands"
        }, 
        {
            "location": "/maker/#arguments", 
            "text": "--mode : Use  dataset  to create a new and  compiler  to subsets.    --dataset_name : Name used to dataset. Default  dataset_example .    --classes_load_file : If not empty load form file the name of classes.    --classes : if empty and --classes_load_file empty the Compiler use all classes inside the dataset. Separete classes wite comma.    --subset_name : name of subset. If not passed will setted as  dataset_name _ serial_data .    --num_images : Number of images from dataset. If negative use --per_images else both negative use all images.    --per_images : percent of images from dataset [-1,100]. If negative use --num_images else both negative use all images.    --scissor : if scissor is on will cut images has configs scissor.json else keep the image on exactly same size (only copy).    --train_proportional_size : size of train, default 70%, setted if test exists.    --validation_proportional_size : size of validation, default 20%, setted if validation exists. Zero if dont want validation    --test_proportional_size : size of validation, default 20%, setted if test exists. Zero if dont want test     --annotation : text annotation used you to describe the subset.", 
            "title": "Arguments"
        }, 
        {
            "location": "/maker/dataset/", 
            "text": "Definition\n\n\nThe \nDataset.py\n is responsible to create the folder and metadata about dataset and the classes received from args params.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nAttributes\n\n\ndataset_name\n : Return the name of dataset.\ntype:String\n \n\n\nclasses\n : List of classes used on dataset \ntype:List\n\n\ndataset_path\n: Path to dataset \ntype:String\n\n\ndataset_md\n: Object dataset_md \ntype:Metadata\n\n\nMethods\n\n\nisADatasetOrSubset\n: Return the path and the type subset or dataset \ntype:[String,String]\n\n\nnormalizePathSubset\n: Normalize the path to by a absolute path", 
            "title": "Dataset class"
        }, 
        {
            "location": "/maker/dataset/#definition", 
            "text": "The  Dataset.py  is responsible to create the folder and metadata about dataset and the classes received from args params.", 
            "title": "Definition"
        }, 
        {
            "location": "/maker/dataset/#params", 
            "text": "args : Args.  type:argparse  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/maker/dataset/#attributes", 
            "text": "dataset_name  : Return the name of dataset. type:String    classes  : List of classes used on dataset  type:List  dataset_path : Path to dataset  type:String  dataset_md : Object dataset_md  type:Metadata", 
            "title": "Attributes"
        }, 
        {
            "location": "/maker/dataset/#methods", 
            "text": "isADatasetOrSubset : Return the path and the type subset or dataset  type:[String,String]  normalizePathSubset : Normalize the path to by a absolute path", 
            "title": "Methods"
        }, 
        {
            "location": "/maker/compiler/", 
            "text": "Definition\n\n\nCompiler.py\n is a class that cut imagens and transfer the files from dataset to subsets.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nAttributes\n\n\ndataset_name\n : Return the name of dataset.\ntype:string\n \n\n\ndataset_path\n : return the path to files \ntype:string\n\n\ndataset_md\n: the dataset metadata \ntype:Metadata\n\n\nsubsets_path\n: return the dataset path \ntype:string\n\n\nsubset_name\n: name received to subsets \ntype:string\n\n\nsubset_path\n: return the subset folder path \ntype:string\n\n\nsubset_md\n: the metadata compiled with informations received by args the dataset path \ntype:Metadata\n\n\nsubset_test_path\n: path to test folder of subset \ntype:string\n\n\nsubset_train_path\n: path to train folder of subset \ntype:string\n\n\nlist_of_classes\n: name of classes manipulated \ntype:string", 
            "title": "Compiler class"
        }, 
        {
            "location": "/maker/compiler/#definition", 
            "text": "Compiler.py  is a class that cut imagens and transfer the files from dataset to subsets.", 
            "title": "Definition"
        }, 
        {
            "location": "/maker/compiler/#params", 
            "text": "args : Args.  type:argparse", 
            "title": "Params"
        }, 
        {
            "location": "/maker/compiler/#attributes", 
            "text": "dataset_name  : Return the name of dataset. type:string    dataset_path  : return the path to files  type:string  dataset_md : the dataset metadata  type:Metadata  subsets_path : return the dataset path  type:string  subset_name : name received to subsets  type:string  subset_path : return the subset folder path  type:string  subset_md : the metadata compiled with informations received by args the dataset path  type:Metadata  subset_test_path : path to test folder of subset  type:string  subset_train_path : path to train folder of subset  type:string  list_of_classes : name of classes manipulated  type:string", 
            "title": "Attributes"
        }, 
        {
            "location": "/maker/seeder/", 
            "text": "Definition\n\n\nSeeder.py\n receive informations from \nCrawler.py\n and seed inside the subsets.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nAttributes\n\n\nclasses_images\n : Classes from metadata.\ntype:string\n \n\n\npath_dataset\n : return the path to files \ntype:string\n\n\npath_subsets\n: return the subset folder path \ntype:string\n\n\nsubsets_list\n: list of subsets in dataset\ntype:List\n\n\nMethods\n\n\nseed\n Execute operatons to seed", 
            "title": "Seeder class"
        }, 
        {
            "location": "/maker/seeder/#definition", 
            "text": "Seeder.py  receive informations from  Crawler.py  and seed inside the subsets.", 
            "title": "Definition"
        }, 
        {
            "location": "/maker/seeder/#params", 
            "text": "args : Args.  type:argparse", 
            "title": "Params"
        }, 
        {
            "location": "/maker/seeder/#attributes", 
            "text": "classes_images  : Classes from metadata. type:string    path_dataset  : return the path to files  type:string  path_subsets : return the subset folder path  type:string  subsets_list : list of subsets in dataset type:List", 
            "title": "Attributes"
        }, 
        {
            "location": "/maker/seeder/#methods", 
            "text": "seed  Execute operatons to seed", 
            "title": "Methods"
        }, 
        {
            "location": "/maker/scissor/", 
            "text": "Definition\n\n\nScissor.py\n open the file and cut to fit exactly in proporcions described in \nscissor.json\n file.\n\n\nParams\n\n\nimage_url\n: the image url to cut or manipulate. \ntype:string\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nAttributes\n\n\noriginal_image_url\n : Return the original url setted  in params.\ntype:Dataset\n \n\n\noriginal_width\n: Original with of image. \ntype:int\n\n\noriginal_height\n: Original height of image. \ntype:int\n\n\nimage_name\n : image name \ntype:string\n\n\nimage_url\n: the url image \ntype:Int\n\n\nimage\n: A copy of original file \ntype:Image\n\n\nwidth\n: width after processed \ntype:Int\n\n\nheight\n: heigth after processed \ntype:Int\n\n\nwindow_height\n: width after processed rate \ntype:Int\n\n\nwindow_width\n: heigth after processed rate \ntype:Int\n\n\nmanipulated\n: if the image was cutted \ntype:bol\n\n\nMethods\n\n\ncut_to_fit\n: Cut the image to \ndestiny_path\n\n\nclose\n: force close the image", 
            "title": "Scissor class"
        }, 
        {
            "location": "/maker/scissor/#definition", 
            "text": "Scissor.py  open the file and cut to fit exactly in proporcions described in  scissor.json  file.", 
            "title": "Definition"
        }, 
        {
            "location": "/maker/scissor/#params", 
            "text": "image_url : the image url to cut or manipulate.  type:string  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/maker/scissor/#attributes", 
            "text": "original_image_url  : Return the original url setted  in params. type:Dataset    original_width : Original with of image.  type:int  original_height : Original height of image.  type:int  image_name  : image name  type:string  image_url : the url image  type:Int  image : A copy of original file  type:Image  width : width after processed  type:Int  height : heigth after processed  type:Int  window_height : width after processed rate  type:Int  window_width : heigth after processed rate  type:Int  manipulated : if the image was cutted  type:bol", 
            "title": "Attributes"
        }, 
        {
            "location": "/maker/scissor/#methods", 
            "text": "cut_to_fit : Cut the image to  destiny_path  close : force close the image", 
            "title": "Methods"
        }, 
        {
            "location": "/crawler/", 
            "text": "Crawler\n\n\nA set of programs that help you create a dataset and crawls in dataset information to compile the classes of your dataset. Try execute the \nMain.py\n\n\nCommands\n\n\nStart executing to create a dataset with two classes.\n\n\npython Main.py --mode crawler,dataset --dataset dataset_example --classes graffiti,street --flickr_tags graffiti,street\\ art;street --num_images 100\n\n\n\nArguments\n\n\nDataset\n\n\n\n\n\n\n--mode\n: Choose de dataset to use in clawer, if no exist will be created. \n\"dataset\"\n if you want only create a dataset and her classes. \n\"crawler\"\n if you create and crawls the classes images from the \ncrawler_mode\n.\n\n\n\n\n\n\n--dataset_name\n: Name used to dataset. Default \ndataset_example\n\n\n\n\n\n\n--classes\n: List of classes to create into dataset. Separated by comma\n\n\n\n\n\n\n--classes_load_file\n: load name of classes by file, one class by line or separated by ; if .csv. try something like the file \ndata/others/crawler/demo_classes.txt\n\n\n\n\n\n\n--crawler_mode\n: The source of images. Default \n\"flickr\"\n.\n\n\n\n\n\n\n--annotation\n: text annotation used you to describe the dataset.\n\n\n\n\n\n\n\n\nFlickr\n\n\n\n\n\n\n--flickr_tags\n: Name of tags useds on flickr, use comma to sum tags on search and (;) to separate de group of tags by classes. The same order of \n--classes\n need by used in \n--flickr_tags\n\n\n\n\n\n\n--flickr_tags_load_file\n: load name of tags by file, tags by line or separated by coma. try something like the file \ndata/others/crawler/demo_flickr_tags.txt\n\n\n\n\n\n\n--num_images\n: Total image per class. Default \n100", 
            "title": "About crawler"
        }, 
        {
            "location": "/crawler/#crawler", 
            "text": "A set of programs that help you create a dataset and crawls in dataset information to compile the classes of your dataset. Try execute the  Main.py", 
            "title": "Crawler"
        }, 
        {
            "location": "/crawler/#commands", 
            "text": "Start executing to create a dataset with two classes.  python Main.py --mode crawler,dataset --dataset dataset_example --classes graffiti,street --flickr_tags graffiti,street\\ art;street --num_images 100", 
            "title": "Commands"
        }, 
        {
            "location": "/crawler/#arguments", 
            "text": "", 
            "title": "Arguments"
        }, 
        {
            "location": "/crawler/#dataset", 
            "text": "--mode : Choose de dataset to use in clawer, if no exist will be created.  \"dataset\"  if you want only create a dataset and her classes.  \"crawler\"  if you create and crawls the classes images from the  crawler_mode .    --dataset_name : Name used to dataset. Default  dataset_example    --classes : List of classes to create into dataset. Separated by comma    --classes_load_file : load name of classes by file, one class by line or separated by ; if .csv. try something like the file  data/others/crawler/demo_classes.txt    --crawler_mode : The source of images. Default  \"flickr\" .    --annotation : text annotation used you to describe the dataset.", 
            "title": "Dataset"
        }, 
        {
            "location": "/crawler/#flickr", 
            "text": "--flickr_tags : Name of tags useds on flickr, use comma to sum tags on search and (;) to separate de group of tags by classes. The same order of  --classes  need by used in  --flickr_tags    --flickr_tags_load_file : load name of tags by file, tags by line or separated by coma. try something like the file  data/others/crawler/demo_flickr_tags.txt    --num_images : Total image per class. Default  100", 
            "title": "Flickr"
        }, 
        {
            "location": "/crawler/flickr/", 
            "text": "Definition\n\n\nFlickr.py\n is a final class used by \nCrawler.py\n to download images from Flickr to a dataset created or open by \nDataset.py\n.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\ncrawler_md\n: the crawler metadata references. \ntype:Metadata\n\n\nclass_name\n: name of class inside of dataset to put all files crawled.\n\n\ntags\n: the tags used to crawls of the param \nclass_name\n.\n\n\nnum_img_to_download\n: Number of images to crawled of this \ntags\n.\n\n\nyear\n: Year of photo on flickr.\n\n\nmonth\n: Month of photo on flickr.\n\n\nday\n: Day of photo on flickr.\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nAttributes\n\n\nimages_metadata\n : List of images and their informations.\ntype:List\n \n\n\n`[{'flickr_id':'91719271212', 'width':500,'height':500,'visible':true,'name':'91719271212_ah1cde.jpg'}]`\n\n\n\ntotal_images\n : Number of images download of tags by class \ntype:List\n.\n\n\nnum_img_to_download\n: Number of images that need by downloaded.", 
            "title": "Flickr class"
        }, 
        {
            "location": "/crawler/flickr/#definition", 
            "text": "Flickr.py  is a final class used by  Crawler.py  to download images from Flickr to a dataset created or open by  Dataset.py .", 
            "title": "Definition"
        }, 
        {
            "location": "/crawler/flickr/#params", 
            "text": "args : Args.  type:argparse  crawler_md : the crawler metadata references.  type:Metadata  class_name : name of class inside of dataset to put all files crawled.  tags : the tags used to crawls of the param  class_name .  num_img_to_download : Number of images to crawled of this  tags .  year : Year of photo on flickr.  month : Month of photo on flickr.  day : Day of photo on flickr.  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/crawler/flickr/#attributes", 
            "text": "images_metadata  : List of images and their informations. type:List    `[{'flickr_id':'91719271212', 'width':500,'height':500,'visible':true,'name':'91719271212_ah1cde.jpg'}]`  total_images  : Number of images download of tags by class  type:List .  num_img_to_download : Number of images that need by downloaded.", 
            "title": "Attributes"
        }, 
        {
            "location": "/crawler/crawler/", 
            "text": "Definition\n\n\nCrawler.py\n is a class that compile informations to \nDataset.py\n and use the \nFlickr.py\n do crawls informations inside each of classes.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nAttributes\n\n\ndataset\n : Return the name of dataset.\ntype:Dataset\n \n\n\ntags_by_class\n : List of tags by class \ntype:List\n\n\nnum_images\n: Number of images by class \ntype:Int\n\n\ncrawler_md\n: Object crawler_md \ntype:Metadata", 
            "title": "Crawler class"
        }, 
        {
            "location": "/crawler/crawler/#definition", 
            "text": "Crawler.py  is a class that compile informations to  Dataset.py  and use the  Flickr.py  do crawls informations inside each of classes.", 
            "title": "Definition"
        }, 
        {
            "location": "/crawler/crawler/#params", 
            "text": "args : Args.  type:argparse  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/crawler/crawler/#attributes", 
            "text": "dataset  : Return the name of dataset. type:Dataset    tags_by_class  : List of tags by class  type:List  num_images : Number of images by class  type:Int  crawler_md : Object crawler_md  type:Metadata", 
            "title": "Attributes"
        }, 
        {
            "location": "/trainer/", 
            "text": "Trainer\n\n\nThe trainer train a model with a dataset or subset create by you. Try execute the \nMain.py\n class.\n\n\nCommands\n\n\nStart to realize a finetuning in image net with the subset \nimagenet_per90_porp_default\n created in maker.\n\n\npython Main.py --model_name model_example_1 --load_data imagenet_per90_porp_default\n\n\n\nArguments\n\n\n\n\n\n\n--model_name\n: Name of model . Default \nname_dataset/name_subset\n_\nserial_number\n.\n\n\n\n\n\n\n--load_model_file\n: load from a .json file the model\n\n\n\n\n\n\n--load_data\n: Use a name of \ndataset\n or from a \nsubsets\n.\n\n\n\n\n\n\n--load_weights\n: Load the weights to model\n\n\n\n\n\n\n--annotation\n: text annotation used you to describe the model.", 
            "title": "About Trainer"
        }, 
        {
            "location": "/trainer/#trainer", 
            "text": "The trainer train a model with a dataset or subset create by you. Try execute the  Main.py  class.", 
            "title": "Trainer"
        }, 
        {
            "location": "/trainer/#commands", 
            "text": "Start to realize a finetuning in image net with the subset  imagenet_per90_porp_default  created in maker.  python Main.py --model_name model_example_1 --load_data imagenet_per90_porp_default", 
            "title": "Commands"
        }, 
        {
            "location": "/trainer/#arguments", 
            "text": "--model_name : Name of model . Default  name_dataset/name_subset _ serial_number .    --load_model_file : load from a .json file the model    --load_data : Use a name of  dataset  or from a  subsets .    --load_weights : Load the weights to model    --annotation : text annotation used you to describe the model.", 
            "title": "Arguments"
        }, 
        {
            "location": "/trainer/callback/", 
            "text": "Definition\n\n\nThe \nCallback.py\n is extension of keras callback and provide metadatas to your model.\n\n\nParams\n\n\nmodel\n: the model. \ntype:Model-\nKeras\n\n\nmodel_metadata\n: Args. \ntype:Metadata\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nMethods\n\n\non_epoch_begin\n: Event when epoch start\n\n\non_epoch_end\n: Event when epoch finish\n\n\non_train_begin\n: Event when train start. The epoch 0 start after.\n\n\non_train_end\n: Event when train end. The last epoch was finished.", 
            "title": "Callback class"
        }, 
        {
            "location": "/trainer/callback/#definition", 
            "text": "The  Callback.py  is extension of keras callback and provide metadatas to your model.", 
            "title": "Definition"
        }, 
        {
            "location": "/trainer/callback/#params", 
            "text": "model : the model.  type:Model- Keras  model_metadata : Args.  type:Metadata  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/trainer/callback/#methods", 
            "text": "on_epoch_begin : Event when epoch start  on_epoch_end : Event when epoch finish  on_train_begin : Event when train start. The epoch 0 start after.  on_train_end : Event when train end. The last epoch was finished.", 
            "title": "Methods"
        }, 
        {
            "location": "/trainer/generator/", 
            "text": "Definition\n\n\nThe \nGenerator.py\n is responsible to create keras generator to train and validation. The job need compile under the informations inside of dataset/subset and model metadata.\n\n\nParams\n\n\nmetadata_model\n: metadata to model. \ntype:Metadata\n\n\nAttributes\n\n\nimageDateGeneratorValidation\n : The DataGenerator keras to validation set.\ntype:ImageDataGenerator\n \n\n\nimageDateGeneratorTrain\n : The DataGenerator keras to train set \ntype:ImageDataGenerator\n\n\nMethods\n\n\ngetTrainGenerator\n: Return the trainer generator \ntype:ImageDataGenerator\n\n\ngetValidationGenerator\n: Return the validatior generator \ntype:ImageDataGenerator", 
            "title": "Generator class"
        }, 
        {
            "location": "/trainer/generator/#definition", 
            "text": "The  Generator.py  is responsible to create keras generator to train and validation. The job need compile under the informations inside of dataset/subset and model metadata.", 
            "title": "Definition"
        }, 
        {
            "location": "/trainer/generator/#params", 
            "text": "metadata_model : metadata to model.  type:Metadata", 
            "title": "Params"
        }, 
        {
            "location": "/trainer/generator/#attributes", 
            "text": "imageDateGeneratorValidation  : The DataGenerator keras to validation set. type:ImageDataGenerator    imageDateGeneratorTrain  : The DataGenerator keras to train set  type:ImageDataGenerator", 
            "title": "Attributes"
        }, 
        {
            "location": "/trainer/generator/#methods", 
            "text": "getTrainGenerator : Return the trainer generator  type:ImageDataGenerator  getValidationGenerator : Return the validatior generator  type:ImageDataGenerator", 
            "title": "Methods"
        }, 
        {
            "location": "/trainer/mananger/", 
            "text": "Definition\n\n\nThe \nMananger.py\n is responsible mananger informations to \nTrainer.py\n class.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nAttributes\n\n\nmodel\n : Return the model Keras loaded.\ntype:Model-\nKeras\n \n\n\nmodel_name\n : Name of this model \ntype:String\n\n\nmetadata\n: Return the metadata from Trainer \ntype:Metadata\n\n\npath_load_subset\n: Path to subset dataset/subset \ntype:String\n\n\npath_model\n: Path to model folder \ntype:String\n\n\npath_model_test\n: Path to model test folder \ntype:String\n\n\npath_model_file\n: Path to model file .json \ntype:String\n\n\npath_model_weights_file\n: Path to weights file .h5 \ntype:String\n\n\npath_dataset\n: Path to dataset folder \ntype:String\n\n\ndataset_set_type\n: Type of set. If is dataset or subset \ntype:String\n\n\nfiles_attached_md\n: Name of files used in train and validation action \ntype:Metadata\n\n\nMethods\n\n\ngetModel\n: Return the model to train \ntype:Model-\nKeras\n\n\ngetCallbacks\n: Return the \nCallback.py\n instance to this train \n[type:Callback]\n\n\nprintModel\n: Print the model\n\n\nsave\n: Execute the command \nsaveWeights\n and \nsaveModel\n\n\nsaveWeights\n: Save the wiegths from model\n\n\nsaveModel\n: Save the model in .json file format\n\n\nconfigFitGenerator\n: get generators and informations used in \nfit_generator\n or \nfit\n method. \n{\"g_train\":type:ImageDataGenerator, \"g_validation\":type:ImageDataGenerator, \"steps_per_epoch_train\":type:Int, \"steps_per_epoch_validation\":type:Int, \"epochs\":type:Int}", 
            "title": "Mananger class"
        }, 
        {
            "location": "/trainer/mananger/#definition", 
            "text": "The  Mananger.py  is responsible mananger informations to  Trainer.py  class.", 
            "title": "Definition"
        }, 
        {
            "location": "/trainer/mananger/#params", 
            "text": "args : Args.  type:argparse  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/trainer/mananger/#attributes", 
            "text": "model  : Return the model Keras loaded. type:Model- Keras    model_name  : Name of this model  type:String  metadata : Return the metadata from Trainer  type:Metadata  path_load_subset : Path to subset dataset/subset  type:String  path_model : Path to model folder  type:String  path_model_test : Path to model test folder  type:String  path_model_file : Path to model file .json  type:String  path_model_weights_file : Path to weights file .h5  type:String  path_dataset : Path to dataset folder  type:String  dataset_set_type : Type of set. If is dataset or subset  type:String  files_attached_md : Name of files used in train and validation action  type:Metadata", 
            "title": "Attributes"
        }, 
        {
            "location": "/trainer/mananger/#methods", 
            "text": "getModel : Return the model to train  type:Model- Keras  getCallbacks : Return the  Callback.py  instance to this train  [type:Callback]  printModel : Print the model  save : Execute the command  saveWeights  and  saveModel  saveWeights : Save the wiegths from model  saveModel : Save the model in .json file format  configFitGenerator : get generators and informations used in  fit_generator  or  fit  method.  {\"g_train\":type:ImageDataGenerator, \"g_validation\":type:ImageDataGenerator, \"steps_per_epoch_train\":type:Int, \"steps_per_epoch_validation\":type:Int, \"epochs\":type:Int}", 
            "title": "Methods"
        }, 
        {
            "location": "/trainer/model/", 
            "text": "Definition\n\n\nThe \nModel.py\n is responsible to  check the mane and path of each model.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nMethods\n\n\nnormalizeModelName\n: Return the name normalized to use or get information in datasets folder \ntype:String\n\n\npathFromModelName\n: Return the path model from name of model", 
            "title": "Model class"
        }, 
        {
            "location": "/trainer/model/#definition", 
            "text": "The  Model.py  is responsible to  check the mane and path of each model.", 
            "title": "Definition"
        }, 
        {
            "location": "/trainer/model/#params", 
            "text": "args : Args.  type:argparse  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/trainer/model/#methods", 
            "text": "normalizeModelName : Return the name normalized to use or get information in datasets folder  type:String  pathFromModelName : Return the path model from name of model", 
            "title": "Methods"
        }, 
        {
            "location": "/trainer/trainer/", 
            "text": "Definition\n\n\nThe \nTrainer.py\n is responsible to train the model and call by \nMain.py\n class.\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nAttributes\n\n\nmananger\n : Return the mananger of trainer.\ntype:Mananger\n \n\n\nmodel\n : Return the model used in train \ntype:Model-\nKeras\n\n\nMethods\n\n\nstart\n: Start the executation compilete in initialize.", 
            "title": "Trainer class"
        }, 
        {
            "location": "/trainer/trainer/#definition", 
            "text": "The  Trainer.py  is responsible to train the model and call by  Main.py  class.", 
            "title": "Definition"
        }, 
        {
            "location": "/trainer/trainer/#params", 
            "text": "args : Args.  type:argparse", 
            "title": "Params"
        }, 
        {
            "location": "/trainer/trainer/#attributes", 
            "text": "mananger  : Return the mananger of trainer. type:Mananger    model  : Return the model used in train  type:Model- Keras", 
            "title": "Attributes"
        }, 
        {
            "location": "/trainer/trainer/#methods", 
            "text": "start : Start the executation compilete in initialize.", 
            "title": "Methods"
        }, 
        {
            "location": "/tester/", 
            "text": "Maker\n\n\nThe tester run the model generated in \nTrainer\n and test the predictions.\n\n\nCommands\n\n\nTo use a subset of test images in a model try:\n\n\npython Main.py --model_name model_example_1 --load_data imagenet_per90_porp_default\n\n\n\nArguments\n\n\n\n\n\n\n--model_name\n: Name or path to a model in datasets folder.\n\n\n\n\n\n\n--load_data\n: Path to any subset or dataset compiled by koopstrap to test, if None we use the test set from subset of train.\n\n\n\n\n\n\n--test_name\n: Name to this test, if empty save a composition from serial number and the dataset tested\n\n\n\n\n\n\n--epoch\n: Set the epoch with weigths that you want save.\n\n\n\n\n\n\n--classes\n: if empty and --classes_load_file empty the Compiler use all classes inside the dataset. Separete classes wite comma.\n\n\n\n\n\n\n--set\n: Choose if the test will use the train, validation or test set of images on subset else selected a dateset the arg will by ignorated.\n\n\n\n\n\n\n--annotation\n: annotation.", 
            "title": "About Tester"
        }, 
        {
            "location": "/tester/#maker", 
            "text": "The tester run the model generated in  Trainer  and test the predictions.", 
            "title": "Maker"
        }, 
        {
            "location": "/tester/#commands", 
            "text": "To use a subset of test images in a model try:  python Main.py --model_name model_example_1 --load_data imagenet_per90_porp_default", 
            "title": "Commands"
        }, 
        {
            "location": "/tester/#arguments", 
            "text": "--model_name : Name or path to a model in datasets folder.    --load_data : Path to any subset or dataset compiled by koopstrap to test, if None we use the test set from subset of train.    --test_name : Name to this test, if empty save a composition from serial number and the dataset tested    --epoch : Set the epoch with weigths that you want save.    --classes : if empty and --classes_load_file empty the Compiler use all classes inside the dataset. Separete classes wite comma.    --set : Choose if the test will use the train, validation or test set of images on subset else selected a dateset the arg will by ignorated.    --annotation : annotation.", 
            "title": "Arguments"
        }, 
        {
            "location": "/tester/mananger/", 
            "text": "Definition\n\n\nThe \nMananger.py\n used to mananger the informations in a test executation.\n\n\nParams\n\n\nArgs\n: args. \ntype:Args\n\n\nlogger\n: logger used in application default value is None. \ntype:Logger\n\n\nMethods\n\n\nsetModel\n: Set the model keras to mananger\n\n\ngetModelWithWeights\n: Return the model of keras compiled with args. \ntype:Model-\nKeras", 
            "title": "Mananger class"
        }, 
        {
            "location": "/tester/mananger/#definition", 
            "text": "The  Mananger.py  used to mananger the informations in a test executation.", 
            "title": "Definition"
        }, 
        {
            "location": "/tester/mananger/#params", 
            "text": "Args : args.  type:Args  logger : logger used in application default value is None.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/tester/mananger/#methods", 
            "text": "setModel : Set the model keras to mananger  getModelWithWeights : Return the model of keras compiled with args.  type:Model- Keras", 
            "title": "Methods"
        }, 
        {
            "location": "/tester/tester/", 
            "text": "Definition\n\n\nThe \nTester.py\n execute the test and compile informations from predictions.\n\n\nParams\n\n\nargs\n: Args. \ntype:Args\n\n\nMethods\n\n\nstar\n: Execute the compilation on initializer classe\n\n\npathFromTestName\n: Return the path of test from a name of test. \ntype:String", 
            "title": "Tester class"
        }, 
        {
            "location": "/tester/tester/#definition", 
            "text": "The  Tester.py  execute the test and compile informations from predictions.", 
            "title": "Definition"
        }, 
        {
            "location": "/tester/tester/#params", 
            "text": "args : Args.  type:Args", 
            "title": "Params"
        }, 
        {
            "location": "/tester/tester/#methods", 
            "text": "star : Execute the compilation on initializer classe  pathFromTestName : Return the path of test from a name of test.  type:String", 
            "title": "Methods"
        }, 
        {
            "location": "/analyzer/", 
            "text": "Analyzer\n\n\nThe analyzer allow you see the information through any ways suchs \ndeep visualization\n and \n1-Top\n activations.\n\n\nCommands\n\n\nSee the 1-top from model and test result.\n\n\npython Main.py --mode top --test_name testing_imagenet_test_set\n\n\n\nSee a deep visualization activation\n\n\npython Main.py --mode visualization --files ../../data/datasets/graffiti/classes/graffiti/4235365635_a5fba2a2d8_o.jpg --model_name model_example_1 --class_name freight\\ car\n\n\n\nArguments\n\n\n\n\n\n\n--mode\n: if you want \ntop\n or \nvisualization\n \n\n\n\n\n\n\n--title\n: title used in images or files to export\n\n\n\n\n\n\nTop arguments\n\n\n\n\n\n\n--number_of_tops\n: Set the number of top suchs 1 or 5.\n\n\n\n\n\n\n--test_name\n: Load the values predictions to top\n\n\n\n\n\n\n--save_histogram_to_csv\n: If you want save the .csv representation.\n\n\n\n\n\n\n--save_histogram_to_png\n: If you want save the .png representation.\n\n\n\n\n\n\n--save_list_image\n: If you save de list of images by class in .csv file.\n\n\n\n\n\n\n--number_limit_to_y\n: Top in chat to y. -1 do default\n\n\n\n\n\n\nVisualization arguments\n\n\n\n\n\n\n--files\n: file or list of images path to by analyze.\n\n\n\n\n\n\n--model_name\n: name of model that want load and view activations\n\n\n\n\n\n\n--modifier\n: you can choose None, 'guided', 'relu','deconv' and 'rectified'. separeted by comma if want multiple\n\n\n\n\n\n\n--class_name\n: name of classe used\n\n\n\n\n\n\n--show_both\n: show image and image with heatmap side by side\n\n\n\n\n\n\n--epoch\n: Set the epoch with weigths that you want save", 
            "title": "About Analyzer"
        }, 
        {
            "location": "/analyzer/#analyzer", 
            "text": "The analyzer allow you see the information through any ways suchs  deep visualization  and  1-Top  activations.", 
            "title": "Analyzer"
        }, 
        {
            "location": "/analyzer/#commands", 
            "text": "See the 1-top from model and test result.  python Main.py --mode top --test_name testing_imagenet_test_set  See a deep visualization activation  python Main.py --mode visualization --files ../../data/datasets/graffiti/classes/graffiti/4235365635_a5fba2a2d8_o.jpg --model_name model_example_1 --class_name freight\\ car", 
            "title": "Commands"
        }, 
        {
            "location": "/analyzer/#arguments", 
            "text": "--mode : if you want  top  or  visualization      --title : title used in images or files to export", 
            "title": "Arguments"
        }, 
        {
            "location": "/analyzer/#top-arguments", 
            "text": "--number_of_tops : Set the number of top suchs 1 or 5.    --test_name : Load the values predictions to top    --save_histogram_to_csv : If you want save the .csv representation.    --save_histogram_to_png : If you want save the .png representation.    --save_list_image : If you save de list of images by class in .csv file.    --number_limit_to_y : Top in chat to y. -1 do default", 
            "title": "Top arguments"
        }, 
        {
            "location": "/analyzer/#visualization-arguments", 
            "text": "--files : file or list of images path to by analyze.    --model_name : name of model that want load and view activations    --modifier : you can choose None, 'guided', 'relu','deconv' and 'rectified'. separeted by comma if want multiple    --class_name : name of classe used    --show_both : show image and image with heatmap side by side    --epoch : Set the epoch with weigths that you want save", 
            "title": "Visualization arguments"
        }, 
        {
            "location": "/analyzer/analyzer/", 
            "text": "Definition\n\n\nAnalizer.py\n is a class that compile information from \nVisualization\n or \nTop\n executation\n\n\nParams\n\n\nargs\n: Args. \ntype:argparse\n\n\nAttributes\n\n\npath_test_folder\n : Return the test folder.\ntype:String\n \n\n\npath_test_predictions_csv\n : Return the path to csv predictions \ntype:String\n\n\npredictions_csv\n: Return the files of predictions \ntype:String\n\n\ntest_md\n: Object test_md \ntype:Metadata\n\n\nnumber_of_classes\n: Return the number of classes used \ntype:Int", 
            "title": "Analyzer class"
        }, 
        {
            "location": "/analyzer/analyzer/#definition", 
            "text": "Analizer.py  is a class that compile information from  Visualization  or  Top  executation", 
            "title": "Definition"
        }, 
        {
            "location": "/analyzer/analyzer/#params", 
            "text": "args : Args.  type:argparse", 
            "title": "Params"
        }, 
        {
            "location": "/analyzer/analyzer/#attributes", 
            "text": "path_test_folder  : Return the test folder. type:String    path_test_predictions_csv  : Return the path to csv predictions  type:String  predictions_csv : Return the files of predictions  type:String  test_md : Object test_md  type:Metadata  number_of_classes : Return the number of classes used  type:Int", 
            "title": "Attributes"
        }, 
        {
            "location": "/analyzer/top_class/", 
            "text": "Definition\n\n\nTopClass.py\n is a class that compile the Top number that you want compile\n\n\nParams\n\n\npath_csv\n: File with predictions \ntype:String\n\n\npath_destiny\n: Path to save the file .csv  \ntype:String\n\n\nnumber_of_tops\n: Number of tops \ntype:Int\n\n\nnumber_of_classes\n: number of classes in model. \ntype:Int\n\n\nlogger\n: logger. \ntype:Logger\n\n\nAttributes\n\n\npath_csv\n : Return teh csv path \ntype:String\n \n\n\npath_destiny\n : Return the path to top file \ntype:String\n\n\nnumber_of_tops\n: Return the number of top \ntype:Int\n\n\nnumber_of_classes\n: Return number of classes \ntype:Int\n\n\nname_file_top_classes\n: Name of file \ntype:String\n\n\nfile_name_top_classes\n: Path and name of file \ntype:String", 
            "title": "TopClass class"
        }, 
        {
            "location": "/analyzer/top_class/#definition", 
            "text": "TopClass.py  is a class that compile the Top number that you want compile", 
            "title": "Definition"
        }, 
        {
            "location": "/analyzer/top_class/#params", 
            "text": "path_csv : File with predictions  type:String  path_destiny : Path to save the file .csv   type:String  number_of_tops : Number of tops  type:Int  number_of_classes : number of classes in model.  type:Int  logger : logger.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/analyzer/top_class/#attributes", 
            "text": "path_csv  : Return teh csv path  type:String    path_destiny  : Return the path to top file  type:String  number_of_tops : Return the number of top  type:Int  number_of_classes : Return number of classes  type:Int  name_file_top_classes : Name of file  type:String  file_name_top_classes : Path and name of file  type:String", 
            "title": "Attributes"
        }, 
        {
            "location": "/analyzer/top_histogram/", 
            "text": "Definition\n\n\nTopHistogram.py\n is a class that compile the Histogram of test\n\n\nParams\n\n\nargs\n: the args used \ntype:Args\n\n\npath_csv\n: Path to csv preditions the file .csv  \ntype:String\n\n\npath_destiny\n: Path to destiny file \ntype:String\n\n\nnumber_of_classes\n: number of classes in model. \ntype:Int\n\n\nlogger\n: logger. \ntype:Logger\n\n\nAttributes\n\n\npath_predictions_csv\n : Return teh csv path \ntype:String\n\n\npath_destiny\n : Return the path to top file \ntype:String\n\n\nnumber_of_tops\n: Return the number of top \ntype:Int\n\n\nnumber_of_classes\n: Return number of classes \ntype:Int\n\n\nnumber_limit_to_y\n: Limit to y \ntype:Int\n\n\nsave_csv\n: Save in .csv file \ntype:Boolean\n\n\nsave_png\n: Save in .png file \ntype:Boolean\n\n\nsave_list_image\n: Save the list of images by class in .csv file \ntype:Boolean\n\n\nfile_name_out_csv\n: path to file .csv \ntype:String\n\n\nfile_name_out_png\n: path to file .png \ntype:String\n\n\nfile_name_out_list_csv\n: path to list of images by class .csv \ntype:String", 
            "title": "TopHistogram class"
        }, 
        {
            "location": "/analyzer/top_histogram/#definition", 
            "text": "TopHistogram.py  is a class that compile the Histogram of test", 
            "title": "Definition"
        }, 
        {
            "location": "/analyzer/top_histogram/#params", 
            "text": "args : the args used  type:Args  path_csv : Path to csv preditions the file .csv   type:String  path_destiny : Path to destiny file  type:String  number_of_classes : number of classes in model.  type:Int  logger : logger.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/analyzer/top_histogram/#attributes", 
            "text": "path_predictions_csv  : Return teh csv path  type:String  path_destiny  : Return the path to top file  type:String  number_of_tops : Return the number of top  type:Int  number_of_classes : Return number of classes  type:Int  number_limit_to_y : Limit to y  type:Int  save_csv : Save in .csv file  type:Boolean  save_png : Save in .png file  type:Boolean  save_list_image : Save the list of images by class in .csv file  type:Boolean  file_name_out_csv : path to file .csv  type:String  file_name_out_png : path to file .png  type:String  file_name_out_list_csv : path to list of images by class .csv  type:String", 
            "title": "Attributes"
        }, 
        {
            "location": "/analyzer/visualization/", 
            "text": "Definition\n\n\nVisualization.py\n is a class that allow you \nsee\n the activation inside the model\n\n\nParams\n\n\nargs\n: the args used \ntype:Args\n\n\nlogger\n: logger. \ntype:Logger\n\n\nAttributes\n\n\npath_images\n : Return the images path \ntype:[String]\n\n\npath_destiny\n : Return the path to top file \ntype:String\n\n\npath_model_json\n: Return the path model json file \ntype:String\n\n\npath_model_weights\n: Return the path model weights file  \ntype:String\n\n\npath_test_model_visualization_file\n: Return the folder where the file will by save \ntype:String\n\n\nserial_number\n: A serial number \ntype:String\n\n\nshow_both\n: Show image side-by-side whit headmap \ntype:Boolean\n\n\nimages_list\n: List of images file \ntype:[String]\n\n\nmodel\n: return the keras model used \ntype:Model-\nKeras\n\n\nfile_name_out_png\n: path to file .png \ntype:String\n\n\nfile_name_out_list_csv\n: path to list of images by class .csv \ntype:String", 
            "title": "Visualization class"
        }, 
        {
            "location": "/analyzer/visualization/#definition", 
            "text": "Visualization.py  is a class that allow you  see  the activation inside the model", 
            "title": "Definition"
        }, 
        {
            "location": "/analyzer/visualization/#params", 
            "text": "args : the args used  type:Args  logger : logger.  type:Logger", 
            "title": "Params"
        }, 
        {
            "location": "/analyzer/visualization/#attributes", 
            "text": "path_images  : Return the images path  type:[String]  path_destiny  : Return the path to top file  type:String  path_model_json : Return the path model json file  type:String  path_model_weights : Return the path model weights file   type:String  path_test_model_visualization_file : Return the folder where the file will by save  type:String  serial_number : A serial number  type:String  show_both : Show image side-by-side whit headmap  type:Boolean  images_list : List of images file  type:[String]  model : return the keras model used  type:Model- Keras  file_name_out_png : path to file .png  type:String  file_name_out_list_csv : path to list of images by class .csv  type:String", 
            "title": "Attributes"
        }, 
        {
            "location": "/system/koopstrap/", 
            "text": "Definition\n\n\nThe koopstrap return a instance of Koopstrap. It is a Dic with many configs what you can see inside the directory \ndata/configs/\n\n\nAttributes\n\n\nconfig\n : the metadata of configuration has default. The file \ndata/configs/kooperstrap.json\n is load to system.\ntype:Dic\n\n\nKeys inside attribute config:\n\n\n{\n    \"path_root\": \"\nPATH\n/kootstrap/\",\n    \"path_log\":\"data/logs/\",\n    \"path_config\":\"data/configs/\",\n    \"path_dataset\":\"data/datasets/\",\n    \"path_model\": \"data/models/\",\n    \"path_test\": \"data/tests/\",\n\n    \"file_exist_count_has_download\":true,\n    \"transfer_file_type\": \"copy\",\n    \"file_order_randomly\": true,\n\n    \"log_level\":\"INFO\",\n    \"version\":\"0.0.1\"\n}\n\n\n\nflickr\n : the metatada of flickr used has default. The file \ndata/configs/flickr.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute flickr:\n\n\n{\n    \"flickr_public_key\":\"\nYOUR_KEY\n\",\n    \"flickr_private_key\":\"\nYOUR_PRIVATE_KEY\n\",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size\":\"larger\",\n    \"flickr_size_minimum\":244,\n    \"flickr_size_maximum\":800,\n    \"safe_mode\":true\n}\n\n\n\nflickr\n : the metatada of flickr used has default. The file \ndata/configs/flickr.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute flickr:\n\n\n{\n    \"flickr_public_key\":\"\nYOUR_KEY\n\",\n    \"flickr_private_key\":\"\nYOUR_PRIVATE_KEY\n\",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size_minimum_width\":500,\n    \"flickr_size_minimum_height\":500,\n    \"flickr_size_maximum_width\":1024,\n    \"flickr_size_maximum_height\":1024,\n    \"safe_mode\":true\n}\n\n\n\nscissor\n : the metatada of scissor used has default. The file \ndata/configs/scissor.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute scissor:\n\n\n{\n    \"target_max_width\":224,\n    \"target_max_height\":224,\n    \"target_min_width\":224,\n    \"target_min_height\":224,\n    \"target_rate\":0.8\n}\n\n\n\ntrainer\n : the metatada of trainer used has default. The file \ndata/configs/trainer.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute scissor:\n\n\n{\n    \"model\": \"VGG16\",\n    \"include_top\": true,\n    \"weights\": \"imagenet\",\n    \"batch_size\": 128,\n    \"target_size\": 224,\n    \"epochs_total\": 2,\n    \"target_loss\":-1.0,\n    \"target_acc\":-1.0,\n    \"save_weights_to_each\":2,\n    \"shuffle\":true\n}\n\n\n\nMethods\n\n\npath_config\n: Return absolute path to configurations of koopstrap. \ntype:String\n\n\npath_test\n: Return absolute path to tests folder. \ntype:String\n\n\npath_log\n: Return absolute path to logs of system. \ntype:String\n\n\npath_model\n: Return absolute path to models folder. \ntype:String\n\n\npath_dataset\n: Return absolute path to all datasets. \ntype:String\n\n\nversion\n: Return version of koopstrap. \ntype:String", 
            "title": "Koopstrap class"
        }, 
        {
            "location": "/system/koopstrap/#definition", 
            "text": "The koopstrap return a instance of Koopstrap. It is a Dic with many configs what you can see inside the directory  data/configs/", 
            "title": "Definition"
        }, 
        {
            "location": "/system/koopstrap/#attributes", 
            "text": "config  : the metadata of configuration has default. The file  data/configs/kooperstrap.json  is load to system. type:Dic  Keys inside attribute config:  {\n    \"path_root\": \" PATH /kootstrap/\",\n    \"path_log\":\"data/logs/\",\n    \"path_config\":\"data/configs/\",\n    \"path_dataset\":\"data/datasets/\",\n    \"path_model\": \"data/models/\",\n    \"path_test\": \"data/tests/\",\n\n    \"file_exist_count_has_download\":true,\n    \"transfer_file_type\": \"copy\",\n    \"file_order_randomly\": true,\n\n    \"log_level\":\"INFO\",\n    \"version\":\"0.0.1\"\n}  flickr  : the metatada of flickr used has default. The file  data/configs/flickr.json  is load to system.  type:Dic  Keys inside attribute flickr:  {\n    \"flickr_public_key\":\" YOUR_KEY \",\n    \"flickr_private_key\":\" YOUR_PRIVATE_KEY \",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size\":\"larger\",\n    \"flickr_size_minimum\":244,\n    \"flickr_size_maximum\":800,\n    \"safe_mode\":true\n}  flickr  : the metatada of flickr used has default. The file  data/configs/flickr.json  is load to system.  type:Dic  Keys inside attribute flickr:  {\n    \"flickr_public_key\":\" YOUR_KEY \",\n    \"flickr_private_key\":\" YOUR_PRIVATE_KEY \",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size_minimum_width\":500,\n    \"flickr_size_minimum_height\":500,\n    \"flickr_size_maximum_width\":1024,\n    \"flickr_size_maximum_height\":1024,\n    \"safe_mode\":true\n}  scissor  : the metatada of scissor used has default. The file  data/configs/scissor.json  is load to system.  type:Dic  Keys inside attribute scissor:  {\n    \"target_max_width\":224,\n    \"target_max_height\":224,\n    \"target_min_width\":224,\n    \"target_min_height\":224,\n    \"target_rate\":0.8\n}  trainer  : the metatada of trainer used has default. The file  data/configs/trainer.json  is load to system.  type:Dic  Keys inside attribute scissor:  {\n    \"model\": \"VGG16\",\n    \"include_top\": true,\n    \"weights\": \"imagenet\",\n    \"batch_size\": 128,\n    \"target_size\": 224,\n    \"epochs_total\": 2,\n    \"target_loss\":-1.0,\n    \"target_acc\":-1.0,\n    \"save_weights_to_each\":2,\n    \"shuffle\":true\n}", 
            "title": "Attributes"
        }, 
        {
            "location": "/system/koopstrap/#methods", 
            "text": "path_config : Return absolute path to configurations of koopstrap.  type:String  path_test : Return absolute path to tests folder.  type:String  path_log : Return absolute path to logs of system.  type:String  path_model : Return absolute path to models folder.  type:String  path_dataset : Return absolute path to all datasets.  type:String  version : Return version of koopstrap.  type:String", 
            "title": "Methods"
        }, 
        {
            "location": "/system/helper/", 
            "text": "Definition\n\n\nThe Helper return a instance of Helper. It content a list of methods that help the manipulation of date for exemple.\n\n\nMethods\n\n\ngetTimeNow\n: Return a string with date in this format \n%Y-%m-%d %H:%M:%S\n. \ntype:String\n\n\ngetSerialNow\n: Return a string with a serial in this format \n%Y%m%d%H%M%S\n. \ntype:String\n\n\nfilePathToList\n: Receive a path of file, open and return a list of lines without \n\\n\n and \n\\r", 
            "title": "Helper class"
        }, 
        {
            "location": "/system/helper/#definition", 
            "text": "The Helper return a instance of Helper. It content a list of methods that help the manipulation of date for exemple.", 
            "title": "Definition"
        }, 
        {
            "location": "/system/helper/#methods", 
            "text": "getTimeNow : Return a string with date in this format  %Y-%m-%d %H:%M:%S .  type:String  getSerialNow : Return a string with a serial in this format  %Y%m%d%H%M%S .  type:String  filePathToList : Receive a path of file, open and return a list of lines without  \\n  and  \\r", 
            "title": "Methods"
        }, 
        {
            "location": "/system/koopstrap/", 
            "text": "Definition\n\n\nThe koopstrap return a instance of Koopstrap. It is a Dic with many configs what you can see inside the directory \ndata/configs/\n\n\nAttributes\n\n\nconfig\n : the metadata of configuration has default. The file \ndata/configs/kooperstrap.json\n is load to system.\ntype:Dic\n\n\nKeys inside attribute config:\n\n\n{\n    \"path_root\": \"\nPATH\n/kootstrap/\",\n    \"path_log\":\"data/logs/\",\n    \"path_config\":\"data/configs/\",\n    \"path_dataset\":\"data/datasets/\",\n    \"path_model\": \"data/models/\",\n    \"path_test\": \"data/tests/\",\n\n    \"file_exist_count_has_download\":true,\n    \"transfer_file_type\": \"copy\",\n    \"file_order_randomly\": true,\n\n    \"log_level\":\"INFO\",\n    \"version\":\"0.0.1\"\n}\n\n\n\nflickr\n : the metatada of flickr used has default. The file \ndata/configs/flickr.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute flickr:\n\n\n{\n    \"flickr_public_key\":\"\nYOUR_KEY\n\",\n    \"flickr_private_key\":\"\nYOUR_PRIVATE_KEY\n\",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size\":\"larger\",\n    \"flickr_size_minimum\":244,\n    \"flickr_size_maximum\":800,\n    \"safe_mode\":true\n}\n\n\n\nflickr\n : the metatada of flickr used has default. The file \ndata/configs/flickr.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute flickr:\n\n\n{\n    \"flickr_public_key\":\"\nYOUR_KEY\n\",\n    \"flickr_private_key\":\"\nYOUR_PRIVATE_KEY\n\",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size_minimum_width\":500,\n    \"flickr_size_minimum_height\":500,\n    \"flickr_size_maximum_width\":1024,\n    \"flickr_size_maximum_height\":1024,\n    \"safe_mode\":true\n}\n\n\n\nscissor\n : the metatada of scissor used has default. The file \ndata/configs/scissor.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute scissor:\n\n\n{\n    \"target_max_width\":224,\n    \"target_max_height\":224,\n    \"target_min_width\":224,\n    \"target_min_height\":224,\n    \"target_rate\":0.8\n}\n\n\n\ntrainer\n : the metatada of trainer used has default. The file \ndata/configs/trainer.json\n is load to system. \ntype:Dic\n\n\nKeys inside attribute scissor:\n\n\n{\n    \"model\": \"VGG16\",\n    \"include_top\": true,\n    \"weights\": \"imagenet\",\n    \"batch_size\": 128,\n    \"target_size\": 224,\n    \"epochs_total\": 2,\n    \"target_loss\":-1.0,\n    \"target_acc\":-1.0,\n    \"save_weights_to_each\":2,\n    \"shuffle\":true\n}\n\n\n\nMethods\n\n\npath_config\n: Return absolute path to configurations of koopstrap. \ntype:String\n\n\npath_test\n: Return absolute path to tests folder. \ntype:String\n\n\npath_log\n: Return absolute path to logs of system. \ntype:String\n\n\npath_model\n: Return absolute path to models folder. \ntype:String\n\n\npath_dataset\n: Return absolute path to all datasets. \ntype:String\n\n\nversion\n: Return version of koopstrap. \ntype:String", 
            "title": "Flickr configuration"
        }, 
        {
            "location": "/system/koopstrap/#definition", 
            "text": "The koopstrap return a instance of Koopstrap. It is a Dic with many configs what you can see inside the directory  data/configs/", 
            "title": "Definition"
        }, 
        {
            "location": "/system/koopstrap/#attributes", 
            "text": "config  : the metadata of configuration has default. The file  data/configs/kooperstrap.json  is load to system. type:Dic  Keys inside attribute config:  {\n    \"path_root\": \" PATH /kootstrap/\",\n    \"path_log\":\"data/logs/\",\n    \"path_config\":\"data/configs/\",\n    \"path_dataset\":\"data/datasets/\",\n    \"path_model\": \"data/models/\",\n    \"path_test\": \"data/tests/\",\n\n    \"file_exist_count_has_download\":true,\n    \"transfer_file_type\": \"copy\",\n    \"file_order_randomly\": true,\n\n    \"log_level\":\"INFO\",\n    \"version\":\"0.0.1\"\n}  flickr  : the metatada of flickr used has default. The file  data/configs/flickr.json  is load to system.  type:Dic  Keys inside attribute flickr:  {\n    \"flickr_public_key\":\" YOUR_KEY \",\n    \"flickr_private_key\":\" YOUR_PRIVATE_KEY \",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size\":\"larger\",\n    \"flickr_size_minimum\":244,\n    \"flickr_size_maximum\":800,\n    \"safe_mode\":true\n}  flickr  : the metatada of flickr used has default. The file  data/configs/flickr.json  is load to system.  type:Dic  Keys inside attribute flickr:  {\n    \"flickr_public_key\":\" YOUR_KEY \",\n    \"flickr_private_key\":\" YOUR_PRIVATE_KEY \",\n    \"flickr_per_page\":500,\n    \"flickr_year_min\":2010,\n    \"flickr_year_max\":2017,\n    \"flickr_size_minimum_width\":500,\n    \"flickr_size_minimum_height\":500,\n    \"flickr_size_maximum_width\":1024,\n    \"flickr_size_maximum_height\":1024,\n    \"safe_mode\":true\n}  scissor  : the metatada of scissor used has default. The file  data/configs/scissor.json  is load to system.  type:Dic  Keys inside attribute scissor:  {\n    \"target_max_width\":224,\n    \"target_max_height\":224,\n    \"target_min_width\":224,\n    \"target_min_height\":224,\n    \"target_rate\":0.8\n}  trainer  : the metatada of trainer used has default. The file  data/configs/trainer.json  is load to system.  type:Dic  Keys inside attribute scissor:  {\n    \"model\": \"VGG16\",\n    \"include_top\": true,\n    \"weights\": \"imagenet\",\n    \"batch_size\": 128,\n    \"target_size\": 224,\n    \"epochs_total\": 2,\n    \"target_loss\":-1.0,\n    \"target_acc\":-1.0,\n    \"save_weights_to_each\":2,\n    \"shuffle\":true\n}", 
            "title": "Attributes"
        }, 
        {
            "location": "/system/koopstrap/#methods", 
            "text": "path_config : Return absolute path to configurations of koopstrap.  type:String  path_test : Return absolute path to tests folder.  type:String  path_log : Return absolute path to logs of system.  type:String  path_model : Return absolute path to models folder.  type:String  path_dataset : Return absolute path to all datasets.  type:String  version : Return version of koopstrap.  type:String", 
            "title": "Methods"
        }, 
        {
            "location": "/tools/", 
            "text": "Tools\n\n\nThe tools help you to \nFix\n a dataset metadata or \nMigrate\n a folder of images to a valid dataset for example.\n\n\nCommands\n\n\nLost the \nmetadata.json\n from a dataset or subset? Try:\n\n\npython Main.py --mode fix --path_origin \nPATH_TO_SUBSET_OR_DATASET\n\n\n\n\nNeed migrate a folder to a dataset in Kootstrap? Try:\n\n\npython Main.py --mode migrate --path_origin \nPATH_FOLDER_WITH_CLASSES\n --path_destiny \nPATH_TO_KOOTSTRAP_FOLDER\n\n\n\n\nCopy or move files to inside a dataset? Try:\n\n\npython Main.py --mode transfer --path_origin \nPATH_FOLDER_WITH_CLASSES\n --path_destiny \nPATH_TO_KOOTSTRAP_FOLDER\n\n\n\n\nArguments\n\n\n\n\n\n\n--mode\n: Use \nfix\n to recovery a metadata, \nmigrate\n to create a new metadata or \ntransfer\n to move files.\n\n\n\n\n\n\n--path_origin\n: Path origin of data, in \nfix\n need be a dataset ou subset. To \nmigrate\n or \ntransfer\n a folder with data to migrate.\n\n\n\n\n\n\n--path_destiny\n: On \nmigrate\n you need set the Kootstrap folder and \ntransfer\n any folder.\n\n\n\n\n\n\n--copy_way\n: To \nmigrate\n or \ntransfer\n if set with \nmove\n after copy will remove the original file.\n\n\n\n\n\n\n--max_files_by_class\n: To \nmigrate\n or \ntransfer\n set a limit to create a dataset.", 
            "title": "About Tools"
        }, 
        {
            "location": "/tools/#tools", 
            "text": "The tools help you to  Fix  a dataset metadata or  Migrate  a folder of images to a valid dataset for example.", 
            "title": "Tools"
        }, 
        {
            "location": "/tools/#commands", 
            "text": "Lost the  metadata.json  from a dataset or subset? Try:  python Main.py --mode fix --path_origin  PATH_TO_SUBSET_OR_DATASET   Need migrate a folder to a dataset in Kootstrap? Try:  python Main.py --mode migrate --path_origin  PATH_FOLDER_WITH_CLASSES  --path_destiny  PATH_TO_KOOTSTRAP_FOLDER   Copy or move files to inside a dataset? Try:  python Main.py --mode transfer --path_origin  PATH_FOLDER_WITH_CLASSES  --path_destiny  PATH_TO_KOOTSTRAP_FOLDER", 
            "title": "Commands"
        }, 
        {
            "location": "/tools/#arguments", 
            "text": "--mode : Use  fix  to recovery a metadata,  migrate  to create a new metadata or  transfer  to move files.    --path_origin : Path origin of data, in  fix  need be a dataset ou subset. To  migrate  or  transfer  a folder with data to migrate.    --path_destiny : On  migrate  you need set the Kootstrap folder and  transfer  any folder.    --copy_way : To  migrate  or  transfer  if set with  move  after copy will remove the original file.    --max_files_by_class : To  migrate  or  transfer  set a limit to create a dataset.", 
            "title": "Arguments"
        }, 
        {
            "location": "/tools/fixmetadata/", 
            "text": "Definition\n\n\nFixMetadata.py\n recovery the file \nmetadata.json\n to \nsubset\n or \ndataset\n.\n\n\nParams\n\n\nargs\n: The args \ntype:args", 
            "title": "FixMetadata class"
        }, 
        {
            "location": "/tools/fixmetadata/#definition", 
            "text": "FixMetadata.py  recovery the file  metadata.json  to  subset  or  dataset .", 
            "title": "Definition"
        }, 
        {
            "location": "/tools/fixmetadata/#params", 
            "text": "args : The args  type:args", 
            "title": "Params"
        }, 
        {
            "location": "/tools/migratedataset/", 
            "text": "Definition\n\n\nMigrateDataset.py\n create a \ndataset\n from a folder.\n\n\nParams\n\n\nargs\n: The args \ntype:args", 
            "title": "MigrateDataset class"
        }, 
        {
            "location": "/tools/migratedataset/#definition", 
            "text": "MigrateDataset.py  create a  dataset  from a folder.", 
            "title": "Definition"
        }, 
        {
            "location": "/tools/migratedataset/#params", 
            "text": "args : The args  type:args", 
            "title": "Params"
        }, 
        {
            "location": "/tools/transfer/", 
            "text": "Definition\n\n\nTransfer.py\n allow you move a lot of files and randomy if you need. Set the number of files too.\n\n\nParams\n\n\nargs\n: The args \ntype:args", 
            "title": "Transfer class"
        }, 
        {
            "location": "/tools/transfer/#definition", 
            "text": "Transfer.py  allow you move a lot of files and randomy if you need. Set the number of files too.", 
            "title": "Definition"
        }, 
        {
            "location": "/tools/transfer/#params", 
            "text": "args : The args  type:args", 
            "title": "Params"
        }, 
        {
            "location": "/about/license/", 
            "text": "MIT License\n\n\nCopyright (c) 2017 Glauco Roberto Munsberg\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.", 
            "title": "License"
        }, 
        {
            "location": "/about/release-notes/", 
            "text": "Release Notes\n\n\nversion 0.0.6\n\n\n\n\nmaker\n: Dataset name only in lower case\n\n\ntools\n: Create tools to migrate old datasets to kootstrap dataset, fixing metadata and transfer files\n\n\nsystem\n: Train,Validation and Test proporcional size in \nkootstrap.json\n\n\nsystem\n: Fixing \nKootstrap.py\n absolute path\n\n\n\n\nversion 0.0.5\n\n\n\n\nanalyzer\n: Allowed to generate 1-Tops likes and deep visualization\n\n\nsystem\n: Fixing name \nKootstrap.py\n\n\nconfigs\n : file name \nkootstrap.json\n fixed\n\n\n\n\nversion 0.0.4\n\n\n\n\ntester\n: Tester.py published\n\n\nsystem\n: Logger.py separete the logs by package\n\n\n\n\nVersion 0.0.3\n\n\n\n\ncrawler\n: Flickr.py train, test and now validation set\n\n\ncrawler\n: with train, test and now \nvalidation set\n\n\nmaker\n  : Dataset.py changet to maker package\n\n\nmaker\n  : now with train, test and now validation set \n\n\ncompiler -\n maker\n : the package \ncompiler\n renomed to \nmaker\n\n\n\n\nVersion 0.0.2\n\n\n\n\ncrawler\n : Crawler.py improved to get images from Flickr \n\n\ncrawler\n : Dataset.py fixing the metadata\n\n\ncrawler\n : Flickr.py improved to flickr.json file configurations\n\n\ncompiler\n: Compiler.py create to create a subsets\n\n\ncompiler\n: Scissor create to cut images\n\n\nconfigs\n : files \nflickr.json\n, \nkoopstrap.json\n and \nscissor.json\n with new dataconfig\n\n\n\n\nVersion 0.0.1\n\n\n\n\nCrawler.py\n create the structure used do dataset\n\n\nProject start baseded on graphium project", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#release-notes", 
            "text": "", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#version-006", 
            "text": "maker : Dataset name only in lower case  tools : Create tools to migrate old datasets to kootstrap dataset, fixing metadata and transfer files  system : Train,Validation and Test proporcional size in  kootstrap.json  system : Fixing  Kootstrap.py  absolute path", 
            "title": "version 0.0.6"
        }, 
        {
            "location": "/about/release-notes/#version-005", 
            "text": "analyzer : Allowed to generate 1-Tops likes and deep visualization  system : Fixing name  Kootstrap.py  configs  : file name  kootstrap.json  fixed", 
            "title": "version 0.0.5"
        }, 
        {
            "location": "/about/release-notes/#version-004", 
            "text": "tester : Tester.py published  system : Logger.py separete the logs by package", 
            "title": "version 0.0.4"
        }, 
        {
            "location": "/about/release-notes/#version-003", 
            "text": "crawler : Flickr.py train, test and now validation set  crawler : with train, test and now  validation set  maker   : Dataset.py changet to maker package  maker   : now with train, test and now validation set   compiler -  maker  : the package  compiler  renomed to  maker", 
            "title": "Version 0.0.3"
        }, 
        {
            "location": "/about/release-notes/#version-002", 
            "text": "crawler  : Crawler.py improved to get images from Flickr   crawler  : Dataset.py fixing the metadata  crawler  : Flickr.py improved to flickr.json file configurations  compiler : Compiler.py create to create a subsets  compiler : Scissor create to cut images  configs  : files  flickr.json ,  koopstrap.json  and  scissor.json  with new dataconfig", 
            "title": "Version 0.0.2"
        }, 
        {
            "location": "/about/release-notes/#version-001", 
            "text": "Crawler.py  create the structure used do dataset  Project start baseded on graphium project", 
            "title": "Version 0.0.1"
        }
    ]
}